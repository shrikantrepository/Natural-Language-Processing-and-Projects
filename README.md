# Natural-Language-Processing-and-Projects
*In ML we can convert categorical features into numeric using data preprocessing techniques.\
If entire feature is in the form of text or paragraph then we can use NLP to get best accuracy of the model.*

## *Why this repository?*
*The main purpose of making this repository is to keep all my NLP concepts and projects at one place, hence keeping my GitHub clean!!*

## *Overview*
This repository consists of NLP codes and Projecs\
Datasets are provided in each of the folders above, and the solution to the problem statements as well...
### *NLP Concepts and codes*
* Tokenization - Converts paragraph into sentenses and words
* Stemming - Help to form base form of the word
* Lemitization - Help to form base form of the word with some meaningful word.
* Bag of Words - Technique to convert text data into vectors ie numbers, so that ML model will be able to understand it and predict the output.
* TF-IDF (Term frequency Inverse document frequency) - Same as Bag of Words however it gives importance to uncommon words
* Word2Vec - Each vector is represented by 32 or more dimentions instead of single number. It preserved semantic information and relationship between different words.

### *NLP Projects*
* Spam_Email_Classifier using BoW and Naive Bayes
* FakeNewsClassifier using TFIDF
* FakeNewsCount_vectorizer ie BoW
* Stock Sentiment Analysis using BoW and Random_Forest
* Word Embedding

## *List of algorithms that are used in these projects --*
* *Classification:*
  * K-Nearest Neighbours
  * Naive Bayes
* *Ensemble*:
  * Random Forest


Do ‚≠ê the repository, if it helped you in anyway.


